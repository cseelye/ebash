#!/usr/bin/env bash

# Bashd is a long running instance of bash which can be used to execute bash commands in a native bash environment 
# even if the caller is not running bash. The advantage to this approach as opposed to alternative approaches with
# calling something like system() directly is it removes the need for fork and exec which oftentimes cannot be
# safely called in some environments. The common use case for this is when a process has massive amounts of memory
# allocated (e.g. 256GB) and tries to fork+exec bash (e.g. via system) the process can easily be OOM'd between the
# fork and the exec while the kernel is going through and marking all the pages as copy on write. Other attempts to
# solve this problem differently with a long-running embedded bash instance suffer different problems which are
# prone to race conditions around pipe handline and process lifetime management.
#
# Bashd is an exceedingly simple solution to this problem which exposes a simple API wherein the caller creates
# a temporary directory in a known queue directory with mktemp(1) or mktemp(3) with a special control file named
# 'options' which contains a set of key=value entries which control what bashd will do. The only required key in
# this file is 'cmdline' which indicates the command that should be invoked by bashd. For a full list of these
# options see the OPTIONS section below. Bashd will then execute the command on behalf of the caller and write
# the command's STDOUT and STDERR into files named 'stdout' and 'stderr' inside that same temporary directory.
# Once the process is completed, it will capture its return code and write that out into a file named 'rc' in
# that same temporary directory.
#
# The caller can simply poll waiting for the creation of the 'rc' file as a signal that the process has finished
# at which point it can then read its stdout, stderr and rc files. The recommended efficient way to achieve this
# is using inotify(7) rather than manually polling waiting for the file to be created. Bashd itself uses inotify(7)
# in order to very efficiently wait for new jobs to be created without having to poll. It also takes care of
# reaping the status of these jobs so as to not have a bunch of unreaped processes filling the process table.
# Finally, bashd is careful to run each process in its own execution environment without sourcing any initialization
# files to ensure as pristine an environment as possible.
#
# OPTIONS
# =======
#
# The following are the keys used to control bashd functionality on a per-command basis.
#
# cmdline
#   The command line to be run. This includes the executable as well as any of its arguments. This could be a simple
#   command, a compound command, or refer to some external and arbitrarily complex script or binary. If the command
#   has whitespace in it be sure to quote the whitespace properly and bashd will honor it.
#
# timeout
#   Optional timeout to kill the command it hasn't exited. If it's a simple number, the duration will be a number in
#   seconds. You may also specify suffixes in the same format the timeout command accepts them. For instance, you
#   might specify 5m or 1h or 2d for 5 minutes, 1 hour, or 2 days, respectively. If the command is timedout then it will
#   have a return code of 124 to match the behavior of the vanilla timeout(1) command. If the command fails to exit
#   after receiving requested signal it will send SIGKILL to the process. If this happens the return code will still be
#   124 since we rely on that return code to indicate that a process timedout and was prematurely terminated.
#
#----------------------------------------------------------------------------------------------------------------------
# FUNCTIONS
#----------------------------------------------------------------------------------------------------------------------

: ${EMSG_PREFIX:=time}
: ${BASHUTILS:=$(readlink -m $(dirname $0))}
source ${BASHUTILS}/bashutils.sh || { echo "Failed to source ${BASHUTILS}/bashutils.sh" ; exit 1 ; }

# handle_job is an internal function which handles a single job. This takes care of actually spawning a clean
# instance of bash and executing the command given to it by the caller and storing the stdout, stderr and return 
# code into files in the specified job directory.
handle_job()
{
    local job="${1}"
    local rc=0
    echo "${BASHPID}" > "${job}/pid"
    
    # Extract options for this job
    local cmdline=$(grep -Po 'cmdline=\K(.*)' ${job}/options)
    local timeout=$(grep -Po 'timeout=\K(.*)' ${job}/options || true)
    einfo "${job} :: Starting ${BASHPID} $(lval cmdline timeout)"

    # Launch brand new session to run the requested command in. It's very important we use setsid here instead of
    # just running the command directly because this ensures the command is run in its own process group and session.
    # This is critical because it guarantees any signals received by that process group stop at that process group and
    # do not percolate up to our long-running bashd process. Otherwise a simple "kill 0" would bring down bashd.
    #
    # NOTE: This code purposefully diables fatal error handling by the "&& rc=0 || rc=$?" idiom. This is because we
    #       do not want a failure in this command to cause bashd itself to exit. Moreover, we don't care about any
    #       set -e error handling or traps since we specifically want a pristine environment and are thus launching
    #       a fresh instance of bash.
    local prefix=""
    [[ -n ${timeout} ]] && prefix="timeout ${timeout}"
    setsid ${prefix} bash --noprofile --norc -c "exec 1>${job}/stdout 2>${job}/stderr; ${cmdline}" && rc=0 || rc=$?
    
    echo "${rc}" >"${job}/rc"
    einfo "${job} :: Complete ${BASHPID} $(lval cmdline timeout rc) stdout=\"$(cat ${job}/stdout)\" stderr=\"$(cat ${job}/stderr)\""
}

# Helper function to kill a stale job or orphaned job.
kill_job()
{
    $(declare_args msg job)
 
    # Get the pid for this job if we can
    local pid=$(cat ${job}/pid || true)
    local delete=$(opt_get d 0)

    # Display what is being killed along with limited context from known files.
    # This is best effort so don't allow a tail failure to cause us to crash.
    ewarn "${job} :: ${msg} ${pid} $(lval delete)"
    tail "${job}"/{options,rc,stdout,stderr} || true

    if process_running ${pid}; then
        ewarn "Killing runing $(lval pid)"
        ekilltree -s=9 ${pid}
        wait "${pid}" || true
    fi
        
    # Optionally remove the directory. Otherwise record failure indicating we killed the job
    if [[ ${delete} -eq 1 ]]; then
        edebug "Deleting ${job}"
        eunmount_recursive "${job}"
        rm --recursive --force --one-file-system "${job}"
    else
        edebug "Marking ${job} as failed"
        echo "$(sigexitcode SIGKILL)" >"${job}/rc"
    fi
}

#----------------------------------------------------------------------------------------------------------------------
# MAIN
#----------------------------------------------------------------------------------------------------------------------

# Parse options including the queue directory to use. This defaults to just '/var/run/bashd'.
# Also parse the default threshold to purge all jobs older than specified time (defaults to 1 day).
# old.
$(declare_args -g)
queue=$(readlink -m $(opt_get q /var/run/bashd))
mkdir -p "${queue}"
purge=$(opt_get p 1d)

# Track the PIDs of the backgrounded processes that bashd launches. These are really only tracked for debugging
# purposes and do not affect the core functionality of bashd itself.
pids=()
PID=${BASHPID}
ebanner "Starting up bashd" QUEUE=queue PID PURGE=purge

# Deal with any orphaned jobs which never got finished due to a crash of bashd. The jobs may not be idempotent
# so we don't want to simply redo the commands. Instead we explicitly mark any orphaned jobs as failed so the caller
# can observe the failure and do whatever they like with the failure.
einfo "Checking for orphaned jobs"
for job in $(find "${queue}" -type d -maxdepth 1); do
    
    # Forcibly mark any orphaned jobs as failures. An orphaned job is one which we explicitly started (as denoted
    # by the presence of the pid file) but never completed (as denoted by the absence of the rc file).
    if [[ -e "${job}/pid" && ! -e "${job}/rc" ]]; then
        kill_job "Orphaned" "${job}"

    # Otherwise, if there is no 'pid' file and no 'rc' file AND an 'options' file then we never even tried to run
    # this job. Go ahead and dispatch the job as normal.
    elif [[ ! -e "${job}/pid" && ! -e "${job}/rc" && -e "${job}/options" ]]; then
        handle_job "${job}" &
        pids+=( $! )
    fi

done

# Enter into an infinite loop waiting for jobs to be created. Feed them into our main event loop which will hand them
# off to handle_job or prune completed jobs as appropriate.
einfo "Starting up main event loop"
inotifywait --recursive --monitor --format "%e:%w%f" -e create "${queue}" | \
while read entry; do

    # Event contains the event type (e.g. CREATE) followed by a colon followed by the path that was created.
    # Parse out the event type and job path.
    event=${entry%%:*}
    job=${entry#*:}
    edebug "$(lval event job pids)"

    # If this is a completed job wait on the pid so that its process state is reaped
    if [[ ${event} == "CREATE" && ${job} == "${queue}"/*/rc ]]; then
        pid=$(cat $(dirname ${job})/pid)
        rc=$(cat ${job})
        wait "${pid}" || true
        array_remove pids ${pid}

    # Otherwise if it's a new job that's been created (as indicated by options file) then dispatch it accordingly.
    elif [[ ${event} == "CREATE" && ${job} == "${queue}"/*/options ]]; then
        handle_job "$(dirname ${job})" &
        pids+=( $! )
    fi

    edebug "$(lval pids)"

    # Purge all jobs older than specified purge interval. Any active jobs older than purge interval are
    # explicitly killed. Find doesn't support an 'older' flag but you can achieve the same effect with
    # the '-not -newer' idiom.
    for job in $(find "${queue}" -type d -maxdepth 1 -not -newermt "${purge}"); do
        kill_job -d=1 "Purging" "${job}"
    done
done

